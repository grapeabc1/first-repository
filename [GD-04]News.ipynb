{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "612c0c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eb5d8d",
   "metadata": {},
   "source": [
    "# 4-9. 프로젝트: Vocabulary Size를 변경해서 시도해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ba75f4",
   "metadata": {},
   "source": [
    "지금까지는 모델을 변경하고, 모델을 조합해서 성능을 올리는 일에 힘썼습니다. 그런데 어쩌면 성능을 높이는 방법은 단순히 모델을 조정하는 일에 한정되지 않을 수 있습니다. 데이터의 전처리는 모델의 성능에 영향을 직접적으로 줍니다. 특히나 Bag of Words를 기반으로 하는 DTM이나 TF-IDF의 경우, 사용하는 단어의 수를 어떻게 결정하느냐에 따라서 성능에 영향을 줄 수 있겠죠.\n",
    "\n",
    "중요도가 낮은 단어들까지 포함해 너무 많은 단어를 사용하는 경우에도 성능이 저하될 수 있고, 반대로 너무 적은 단어들을 사용해도 성능이 저하될 수 있습니다. 이렇게 변화된 단어의 수는 또 어떤 모델을 사용하느냐에 따라 유리할 수도, 불리할 수도 있습니다.\n",
    "\n",
    "단어의 수에 따라서 모델의 성능이 어떻게 변하는지 테스트해 봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2b0685",
   "metadata": {},
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=10000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7158d8c0",
   "metadata": {},
   "source": [
    "앞서 num_words로 사용할 단어의 수를 조정할 수 있다는 것을 배웠습니다. 빈도수가 많은 순서대로 나열했을 때, num_words의 인자로 준 정숫값만큼의 단어를 사용하고 나머지 단어는 전부 unk로 처리하는 원리였었죠.\n",
    "\n",
    "아래의 두 가지 경우에 대해서 지금까지 사용했던 모델들의 정확도를 직접 확인해 보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e6f255",
   "metadata": {},
   "source": [
    "## 라이브러리 버전을 확인해 봅니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d06888",
   "metadata": {},
   "source": [
    "사용할 라이브러리 버전을 둘러봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ee1e1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "3.4.3\n",
      "0.11.2\n",
      "1.22.2\n",
      "1.3.3\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import matplotlib\n",
    "import seaborn \n",
    "import numpy \n",
    "import pandas\n",
    "import sklearn\n",
    "\n",
    "print(tensorflow.__version__)\n",
    "print(matplotlib.__version__)\n",
    "print(seaborn.__version__)\n",
    "print(numpy.__version__)\n",
    "print(pandas.__version__)\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db0fd7b",
   "metadata": {},
   "source": [
    "## 1. 모든 단어 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8919346",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모든 단어 사용\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=None, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b83446ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#로이터 뉴스 데이터는 '단어'를 key값으로, 고유한 '정수'를 value로 가지는 dictionary를 제공합니다. 이를 word_index로 저장\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b6d4be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0,1,2는 사용중이라 +3\n",
    "index_to_word = {index + 3 : word for word, index in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4729739b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_to_word에 숫자 0은 <pad>, 숫자 1은 <sos>, 숫자 2는 <unk>를 넣어줍니다.\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "    index_to_word[index]=token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8eea0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체훈련용데이터를 텍스트데이터로 변환\n",
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train = decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f95affb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체테스트용데이터를 텍스트데이터로 변환\n",
    "decoded = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_test = decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abb33cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#테스트 데이터에 대한 정확도를 측정하기 위해서는 훈련 데이터와 동일한 전처리를 거쳐야 합니다. \n",
    "#다시 말해 테스트 데이터도 TF-IDF 행렬로 변환해 주어야 합니다. \n",
    "#그 후 해당 행렬과 predict() 함수를 통해 예측값을 얻어 정확도를 측정합니다.\n",
    "\n",
    "dtmvector = CountVectorizer()\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "x_test_dtm = dtmvector.transform(x_test) #테스트 데이터를 DTM으로 변환\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm) #DTM을 TF-IDF 행렬로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "564ea614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.5997328584149599\n"
     ]
    }
   ],
   "source": [
    "# 나이브 베이즈 분류기\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = model.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97841394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7649154051647373\n"
     ]
    }
   ],
   "source": [
    "#CNB\n",
    "\n",
    "cb = ComplementNB()\n",
    "cb.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = cb.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52504357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.813446126447017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#로지스틱 회귀\n",
    "\n",
    "lr = LogisticRegression(C=10000, penalty='l2')\n",
    "lr.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = lr.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffc94ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7764915405164737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#서포트 벡터 머신\n",
    "\n",
    "lsvc = LinearSVC(C=1000, penalty='l1', max_iter=500, dual=False)\n",
    "lsvc.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = lsvc.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c60e64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6211041852181657\n"
     ]
    }
   ],
   "source": [
    "#결정 트리\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "tree.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = tree.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "812e601e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6544968833481746\n"
     ]
    }
   ],
   "source": [
    "#랜덤 포레스트\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "forest.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = forest.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "847fc5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7702582368655387\n"
     ]
    }
   ],
   "source": [
    "#그래디언트 부스팅 트리\n",
    "\n",
    "grbt = GradientBoostingClassifier(random_state=0) # verbose=3\n",
    "grbt.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = grbt.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f19b2868",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.8187889581478184\n"
     ]
    }
   ],
   "source": [
    "#보팅\n",
    "\n",
    "voting_classifier = VotingClassifier(estimators=[\n",
    "         ('lr', LogisticRegression(C=10000, penalty='l2')),\n",
    "        ('cb', ComplementNB()),\n",
    "        ('grbt', GradientBoostingClassifier(random_state=0))\n",
    "], voting='soft', n_jobs=-1)\n",
    "voting_classifier.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = voting_classifier.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5fdc72",
   "metadata": {},
   "source": [
    "## 2. 빈도수 상위 5,000개의 단어만 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ef76002",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5000 단어 사용\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=5000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f417799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#로이터 뉴스 데이터는 '단어'를 key값으로, 고유한 '정수'를 value로 가지는 dictionary를 제공합니다. 이를 word_index로 저장\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27cb79e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0,1,2는 사용중이라 +3\n",
    "index_to_word = {index + 3 : word for word, index in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3290fb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_to_word에 숫자 0은 <pad>, 숫자 1은 <sos>, 숫자 2는 <unk>를 넣어줍니다.\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "    index_to_word[index]=token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf778b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체훈련용데이터를 텍스트데이터로 변환\n",
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train = decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe7683a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체테스트용데이터를 텍스트데이터로 변환\n",
    "decoded = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_test = decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d82b35b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#테스트 데이터에 대한 정확도를 측정하기 위해서는 훈련 데이터와 동일한 전처리를 거쳐야 합니다. \n",
    "#다시 말해 테스트 데이터도 TF-IDF 행렬로 변환해 주어야 합니다. \n",
    "#그 후 해당 행렬과 predict() 함수를 통해 예측값을 얻어 정확도를 측정합니다.\n",
    "\n",
    "dtmvector = CountVectorizer()\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "x_test_dtm = dtmvector.transform(x_test) #테스트 데이터를 DTM으로 변환\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm) #DTM을 TF-IDF 행렬로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f7bf54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#테스트 데이터에 대한 정확도를 측정하기 위해서는 훈련 데이터와 동일한 전처리를 거쳐야 합니다. \n",
    "#다시 말해 테스트 데이터도 TF-IDF 행렬로 변환해 주어야 합니다. \n",
    "#그 후 해당 행렬과 predict() 함수를 통해 예측값을 얻어 정확도를 측정합니다.\n",
    "\n",
    "x_test_dtm = dtmvector.transform(x_test) #테스트 데이터를 DTM으로 변환\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm) #DTM을 TF-IDF 행렬로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e00f605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6731967943009796\n"
     ]
    }
   ],
   "source": [
    "# 나이브 베이즈 분류기\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = model.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58cc4524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7707034728406055\n"
     ]
    }
   ],
   "source": [
    "#CNB\n",
    "\n",
    "cb = ComplementNB()\n",
    "cb.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = cb.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62092c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.8058771148708815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#로지스틱 회귀\n",
    "\n",
    "lr = LogisticRegression(C=10000, penalty='l2')\n",
    "lr.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = lr.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6ff784c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7680320569902048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#서포트 벡터 머신\n",
    "\n",
    "lsvc = LinearSVC(C=1000, penalty='l1', max_iter=500, dual=False)\n",
    "lsvc.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = lsvc.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "69c8e906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6179875333926982\n"
     ]
    }
   ],
   "source": [
    "#결정 트리\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "tree.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = tree.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f89621e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.701246660730187\n"
     ]
    }
   ],
   "source": [
    "#랜덤 포레스트\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "forest.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = forest.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78a37b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.767586821015138\n"
     ]
    }
   ],
   "source": [
    "#그래디언트 부스팅 트리\n",
    "\n",
    "grbt = GradientBoostingClassifier(random_state=0) # verbose=3\n",
    "grbt.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = grbt.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a7466dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.8161175422974176\n"
     ]
    }
   ],
   "source": [
    "#보팅\n",
    "\n",
    "voting_classifier = VotingClassifier(estimators=[\n",
    "         ('lr', LogisticRegression(C=10000, penalty='l2')),\n",
    "        ('cb', ComplementNB()),\n",
    "        ('grbt', GradientBoostingClassifier(random_state=0))\n",
    "], voting='soft', n_jobs=-1)\n",
    "voting_classifier.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = voting_classifier.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fdde19",
   "metadata": {},
   "source": [
    "## 3. 직접 단어 개수를 설정해서 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22a3c8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2500 단어 사용\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=2500, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50179c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#로이터 뉴스 데이터는 '단어'를 key값으로, 고유한 '정수'를 value로 가지는 dictionary를 제공합니다. 이를 word_index로 저장\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "07f6de9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0,1,2는 사용중이라 +3\n",
    "index_to_word = {index + 3 : word for word, index in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e52849f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_to_word에 숫자 0은 <pad>, 숫자 1은 <sos>, 숫자 2는 <unk>를 넣어줍니다.\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "    index_to_word[index]=token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bdb71cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체훈련용데이터를 텍스트데이터로 변환\n",
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train = decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59947355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체테스트용데이터를 텍스트데이터로 변환\n",
    "decoded = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_test = decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e04b119d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#테스트 데이터에 대한 정확도를 측정하기 위해서는 훈련 데이터와 동일한 전처리를 거쳐야 합니다. \n",
    "#다시 말해 테스트 데이터도 TF-IDF 행렬로 변환해 주어야 합니다. \n",
    "#그 후 해당 행렬과 predict() 함수를 통해 예측값을 얻어 정확도를 측정합니다.\n",
    "\n",
    "dtmvector = CountVectorizer()\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "x_test_dtm = dtmvector.transform(x_test) #테스트 데이터를 DTM으로 변환\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm) #DTM을 TF-IDF 행렬로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ed2cea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#테스트 데이터에 대한 정확도를 측정하기 위해서는 훈련 데이터와 동일한 전처리를 거쳐야 합니다. \n",
    "#다시 말해 테스트 데이터도 TF-IDF 행렬로 변환해 주어야 합니다. \n",
    "#그 후 해당 행렬과 predict() 함수를 통해 예측값을 얻어 정확도를 측정합니다.\n",
    "\n",
    "x_test_dtm = dtmvector.transform(x_test) #테스트 데이터를 DTM으로 변환\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm) #DTM을 TF-IDF 행렬로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "22c2249b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6905609973285841\n"
     ]
    }
   ],
   "source": [
    "# 나이브 베이즈 분류기\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = model.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "75970712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7609082813891362\n"
     ]
    }
   ],
   "source": [
    "#CNB\n",
    "\n",
    "cb = ComplementNB()\n",
    "cb.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = cb.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e4405402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7849510240427426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#로지스틱 회귀\n",
    "\n",
    "lr = LogisticRegression(C=10000, penalty='l2')\n",
    "lr.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = lr.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "818ab3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7471059661620659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#서포트 벡터 머신\n",
    "\n",
    "lsvc = LinearSVC(C=1000, penalty='l1', max_iter=500, dual=False)\n",
    "lsvc.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = lsvc.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5cbbfddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6260017809439002\n"
     ]
    }
   ],
   "source": [
    "#결정 트리\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "tree.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = tree.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "505e6539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.705253784505788\n"
     ]
    }
   ],
   "source": [
    "#랜덤 포레스트\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "forest.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = forest.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e6cd9e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7666963490650045\n"
     ]
    }
   ],
   "source": [
    "#그래디언트 부스팅 트리\n",
    "\n",
    "grbt = GradientBoostingClassifier(random_state=0) # verbose=3\n",
    "grbt.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = grbt.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "84e756e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.8040961709706145\n"
     ]
    }
   ],
   "source": [
    "#보팅\n",
    "\n",
    "voting_classifier = VotingClassifier(estimators=[\n",
    "         ('lr', LogisticRegression(C=10000, penalty='l2')),\n",
    "        ('cb', ComplementNB()),\n",
    "        ('grbt', GradientBoostingClassifier(random_state=0))\n",
    "], voting='soft', n_jobs=-1)\n",
    "voting_classifier.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = voting_classifier.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3643d4",
   "metadata": {},
   "source": [
    "단어수별 모델별 정리\n",
    "\n",
    "1. 모든 단어 사용\n",
    "\n",
    "나이브 베이즈 분류기: 59\n",
    "\n",
    "CNB: 76\n",
    "\n",
    "로지스틱 회귀: 81\n",
    "\n",
    "서포트 벡터 머신: 77\n",
    "\n",
    "결정 트리: 62\n",
    "\n",
    "랜덤 프레스트: 65\n",
    "\n",
    "그래디언트 부스팅 트리:77\n",
    "\n",
    "보팅: 81\n",
    "\n",
    "\n",
    "2. 5000개 단어 사용\n",
    "\n",
    "나이브 베이즈 분류기: 67\n",
    "\n",
    "CNB:77\n",
    "\n",
    "로지스틱 회귀: 80\n",
    "\n",
    "서포트 벡터 머신: 76\n",
    "\n",
    "결정 트리: 61\n",
    "\n",
    "랜덤 프레스트: 70\n",
    "\n",
    "그래디언트 부스팅 트리: 76\n",
    "\n",
    "보팅: 81\n",
    "\n",
    "\n",
    "3. 2500개 단어 사용\n",
    "\n",
    "나이브 베이즈 분류기: 69\n",
    "\n",
    "CNB: 76\n",
    "\n",
    "로지스틱 회귀: 78\n",
    "\n",
    "서포트 벡터 머신: 74\n",
    "\n",
    "결정 트리:62\n",
    "\n",
    "랜덤 프레스트: 70\n",
    "\n",
    "그래디언트 부스팅 트리: 76\n",
    "\n",
    "보팅: 80\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7122f73d",
   "metadata": {},
   "source": [
    "단어 수와 관계없이 로지스틱 회귀랑 보팅 모델이 정확도 약 80% 정도로 가장 성능이 좋았고,\n",
    "\n",
    "모델별로 단어수가 적어졌을 때 정확도가 더 높아진 경우도 있었고, ex. 나이브 베이즈 분류기\n",
    "\n",
    "그 반대로 단어수가 많아졌을 떄 정확도가 더 높아진 경우도 있었다. ex. 로지스틱 회귀, 서포트 벡터 머신\n",
    "\n",
    "단어 수보다는 모델이 더 중요한 것 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4abec76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7e34a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
